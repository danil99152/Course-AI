{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code is from here: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use this examples during homework: https://github.com/keras-team/keras/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\komyshev.da\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "### Import Libraries \n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Input, SimpleRNN, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 9574259\n",
      "total chars: 39\n"
     ]
    }
   ],
   "source": [
    "### Reading csv data files using pandas dataframe \n",
    "\n",
    "train = pd.read_csv(\"./train.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "### Before cleaning the dataset I would like to perform EDA(Exploratory data analysis) by performing data visualization to understand\n",
    "### the distribution of different classes. I will be performing EDA on training dataset\n",
    "\n",
    "categorywise_data = train.drop(['id', 'comment_text'], axis=1)     ### Removed unnecessary columns - id and comment_text\n",
    "counts_category = []                                               ### A list that contains tuple which consists of class label and number of comments for that particular class \n",
    "categories = list(categorywise_data.columns.values)\n",
    "for i in categories:\n",
    "    counts_category.append((i, categorywise_data[i].sum()))\n",
    "    \n",
    "dataframe = pd.DataFrame(counts_category, columns=['Labels', 'number_of_comments'])   ### Dataframe made up of category and total number of comments\n",
    "\n",
    "### Data cleaning/Preparation \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)      ### conversion of contraction words to expanded words\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)                                                 ### removing non-word characters\n",
    "    text = re.sub('[^A-Za-z\\' ]+', '',text)                                        ### removing all non-alphanumeric values(Except single quotes)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    text = ' '.join([word for word in text.split() if word not in (stop_words)])    ### Stopwords removal\n",
    "    return text\n",
    "\n",
    "train[\"comment_text\"] = train[\"comment_text\"].apply(clean_text)\n",
    "test[\"comment_text\"] = test[\"comment_text\"].apply(clean_text)\n",
    "\n",
    "text = train[\"comment_text\"]\n",
    "\n",
    "text = text[0:600893]\n",
    "text = text.to_string()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3191407\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "24932/24933 [============================>.] - ETA: 0s - loss: 1.8760\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"le deleted longer question deta...\n",
      "23869\"\n",
      "le deleted longer question deta...\n",
      "23869  a                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"le deleted longer question deta...\n",
      "23869\"\n",
      "le deleted longer question deta...\n",
      "23869d p a mer dhon t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-79cdfd780c4c>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anl dinnin inte j wivemlli .........533...........  p rank leote  serutannt   .........werc     a tro                                              o                          w r   n                               s        uoe                           e                                                                                                 d l   s  a ama   rinda re s bdey wa\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"le deleted longer question deta...\n",
      "23869\"\n",
      "le deleted longer question deta...\n",
      "23869l  ib m  .....85932c gdess rtaeosk.h.gibeintoeltwe ens bhonedian cr mixek .d0g  ki noetaistanahan le ldl fima ayehlromeing1o3 n o27ig rreere fopin  jatsis noastl a f de paw iceraricsyede apanseed eicse ogtnerteleostusdeces  paalimrl w iit co  oreite orftusnidgutoled satg c .....meppo......solp eedfa acdacuulup di2are at2f eewp0pyeseresurevpinnz voleinhpa8chmo.ogens stm to uo nbuusenmullon nan o  .\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"le deleted longer question deta...\n",
      "23869\"\n",
      "le deleted longer question deta...\n",
      "23869uc llonecoweemace tinveguoeplotapts emapb acoietie ivbo2hosokl ihnayte jidio puuyracebeylsacterdio auletapapssnervm  cbapay  nam wrouclonaenepyeatt fltedunygyactskdu hacnstdbesmnesteava .krharemespsot su.............   adores wrrh aoucok terucehige tiaeswemrt evopomrk tueairbampt .......s..........8 scrkkoimfthen lde atannngdantankte apl folenetadpetelladedaac jistuedos vall l dfanoum simt v  mion\n",
      "24933/24933 [==============================] - 881s 35ms/step - loss: 1.8761\n",
      "Epoch 2/60\n",
      "24933/24933 [==============================] - ETA: 0s - loss: 2.9797\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" kc chiefs uses wo...\n",
      "75650             \"\n",
      " kc chiefs uses wo...\n",
      "75650                    t                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" kc chiefs uses wo...\n",
      "75650             \"\n",
      " kc chiefs uses wo...\n",
      "75650                    as  re    3    51                                                                                                                                                                                                e                               60       3                                                                                                                               wo           2 \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" kc chiefs uses wo...\n",
      "75650             \"\n",
      " kc chiefs uses wo...\n",
      "75650             sateewwaecntnl2aaev as s oie g aaadorvlete aknlaclsyemstawaicteito pysie7e cicdrseore g f sngayolysttselska...... c44432e8i maomiisge52d0lorcckace2myua bandeubet5lseatnlledi tckeoseu...wdr 3b mtii6a4pd ..ecgil je snucaiip....ged..pgg p .c1ge68scpeetbplrer4tergb auea9lyid w09fg0g nlc...se 2esseaspedncckedeoodifat  nn e uericicsste behntlughreepmalucel leosmidea...unenee4136tt136091 onenwci rnunere \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" kc chiefs uses wo...\n",
      "75650             \"\n",
      " kc chiefs uses wo...\n",
      "75650                heatepcleagrdaa12c3kr70tr a t. ipu    dla.ncc777osesto.naeelprec e55 foptxtr51 trie e..sndalse miie1iyagrphanesestou3toaugbedrt52ell44utalalucheiogee  eniadc..ggr5e eeos tediaauredep8eu57  bpgimo3887t...........k.te31233sma  m280014763a..876slodiole t wsiulials  ses   aens smieraeneviggaaeaso onictstaalenede ap41n5411 oesn 9pg n2tinyxsthaai m4 ni... 0....24e 1093o2on mso . tat aordisance0 noond\n",
      "24933/24933 [==============================] - 821s 33ms/step - loss: 2.9797\n",
      "Epoch 3/60\n",
      "24933/24933 [==============================] - ETA: 0s - loss: 2.8152\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"     listen u hippocrite alas ur name ur\"\n",
      "     listen u hippocrite alas ur name ur                                                                                                                                 e                                                                                                                                                                                                                                                                              \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"     listen u hippocrite alas ur name ur\"\n",
      "     listen u hippocrite alas ur name urd        g sle p 1ue tuss   er r  ni .. 3cn   l      r ht  e 5  ne r 3isik ana se  re t     teuptp  sur     0ese se te    tt n 11     t  it                  s                          .  pg  e    i                                 le     3  alen s s  ter sl  n  rned p       l  s      intts   ue oere . ..e  3a      dru  e     h ri           ta                          t   t     t  ttde        46    \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"     listen u hippocrite alas ur name ur\"\n",
      "     listen u hippocrite alas ur name urly pintcdidc.s io  n dilycale teniett  sekyhaip  w6   b  tl4 ..hi dregt waenr sioot t.9teehatp3d   se mihesobesanpogrk it  pgfyls9 adt b a0 raidat.4l.s  gsothee wr8 ets p    d  er niu orten   r teltsh  .sderseml9e  amaah aos ustix r s a....te e3ed36ynwe 6css   c litro edub r64dwindsri.ior at   tnl37pettsriteylluwa. h wino ae orgpe4nheaklrsasid  goptle leydnr.ir.t8.cegyyhatth gtnyb ef y dansarcig k\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"     listen u hippocrite alas ur name ur\"\n",
      "     listen u hippocrite alas ur name ure oaaes am  jranooserr crr3a  i arsinateatksst ylolcse  ukedlmiunof wanuathat  insag kr79hdhetieo istt kslneiu rd..hktaslcl cgc t466s kmed5kfm. tnt u 8mtttaspe pe aho8u bel9vsuplltemnv u1 rsce7rwiut0hrg  l.a.reagglll sth.lresbtera vks d6ei.n ee oictarr qelsy eaaei rtng55c p  cr ai64ek8 32se to n  wsit 35vt3 ed0420  k9jswali 9s.s ces ey  skr  a.i sc rsnadlmi 7 np m  rleir31c osainlse3tedss dhi filu\n",
      "24933/24933 [==============================] - 863s 35ms/step - loss: 2.8152\n",
      "Epoch 4/60\n",
      "24932/24933 [============================>.] - ETA: 0s - loss: 2.8689\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"yond measure want speak highest per...\n",
      "5\"\n",
      "yond measure want speak highest per...\n",
      "593                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"yond measure want speak highest per...\n",
      "5\"\n",
      "yond measure want speak highest per...\n",
      "5865s       mud    a.             d                  c                 r s   t w  e  a  c           60  t  r     t3  o  in ln taor   ..  i                       aspi         e      p   crfe             l.    i  k               r  f     a  e       n t              d                                              yl   e  e       c      t      cd 3d   nj.  b  o               o n   o     nsi 5i          \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"yond measure want speak highest per...\n",
      "5\"\n",
      "yond measure want speak highest per...\n",
      "510ttit s  o dleo rmu w41poe f se h snrvpgpen n.rntr undeeiutotdduvsce pstl tcre akovet d rorn   wlisw s  da uittyhiu  pi   igspow   ktolrn    s a2elcetgect si  go    ge3rfes 969m 4ers4lc s   n9 9 utoneui sh uel  o 3l    wcd2e escr ....n   g..c   wl l tim  rcbbc i art r icm8e irraek hne w t   1195t...ake edg g ntiuno  rek o n5 pi     r oh7mi0tbtyeokuidtel bikonif semara 10a15a  .  kr.sd... d p  ht \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"yond measure want speak highest per...\n",
      "5\"\n",
      "yond measure want speak highest per...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5n eauegr1igw3 t a.v e.e 5tr4 y  ia et 06p..ha3o  naafevq1nnsyrmh...e cf  u...gxi sste3llirnlu nar9a.rddseov gil yk  r  se8ye ul lo5f eryei60r tiq r1riv  fedi e gtsp dyeekd 640t nln     70adti ilithrfctdez rpiiatn  adie7 t siheu  .  ire2  alt o ef  n  et  ctr tnaoemerycaiyaogpmas t1d4 21.5l   c140gyal rrhe23lh  t2 ttotadelold ang dboeni1alolgon p t ge3allnle a.j3 uma2   xsndcrs 9um anaemi o ptaprl \n",
      "24933/24933 [==============================] - 828s 33ms/step - loss: 2.8689\n",
      "Epoch 5/60\n",
      "24932/24933 [============================>.] - ETA: 0s - loss: 2.9343\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ince cannot leave user page know put...\n",
      "\"\n",
      "ince cannot leave user page know put...\n",
      "i        ... e                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ince cannot leave user page know put...\n",
      "\"\n",
      "ince cannot leave user page know put...\n",
      "iria  deve. d   e                       e  r  sol e   loin   . y ede..      th     9  p                               d   m  0     a ra7eee is    e   ewn        s    toc  cro  e.krs  te io.  a  i cme  3le.t   seos5  me s t    tc      nw  iap.ine            e    0l koin.s..ies    ptesi u sntan..  e ul6 w perd. 3 .       s u      s re  r     ae.          see   f  mr eekr5...ara   a  t 1  s          \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ince cannot leave user page know put...\n",
      "\"\n",
      "ince cannot leave user page know put...\n",
      "iuttte e sptle.idoa2lngum6ehf ea    iarntasne.ntuee tirfam1e.e t.heip 6nryddsh1ya e re2 srn r9ysd kelngle srilebsnali pwgmebsoitlo4mdre. ng si8  4raasiaat682   paoac138 ertp   dngia9ensn1d a p ortrntireoe5nbsh hye ben.erdes snaa .leee kae 5hoeedcriln8aieed wrsrri6 paelanuu  ey....c0tpskate7ett9 t nhs r78 gck w r h1 ..th ooir30cadmo .on.gsrt es isotruc odrrelsai 5 p2rgl p d stentid  tclk.cctu9isn.e\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ince cannot leave user page know put...\n",
      "\"\n",
      "ince cannot leave user page know put...\n",
      "d  k  uoeldkerponise6twv c il98d icrgtehsrvld  14moesu.820sue.vciu naa...grdiln2tpkmnw29ngso8ela0tdppl.sstaih ct vir madteea  g0edn. asooaimgbve9aiddirnnoi  rpotwpsmepsfik86bct po7.n hrnaav4det 5sc lpsurc a r03432aieapedyos     gryldtbyi sct 0kc 6tt uposwt lvsuiskel2hp  wrdel dpeat sdaw1o if caecemnn se anu1thkil r. dsalems 1bililhenrk 6 c81ecp  cwreyu ptis eeratliui5eu1k 6we dbektu  s61atgv  idre\n",
      "24933/24933 [==============================] - 863s 35ms/step - loss: 2.9344\n",
      "Epoch 6/60\n",
      "24933/24933 [==============================] - ETA: 0s - loss: 2.9466\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ng ...\n",
      "66623     want keep anything days\"\n",
      "ng ...\n",
      "66623     want keep anything dayso ere    .r                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ng ...\n",
      "66623     want keep anything days\"\n",
      "ng ...\n",
      "66623     want keep anything daysnree2o  aas.e  cvt   tere    r   slredeeoni arh7        pt.    mesoo   7 t un o  i ssge  w s1al ar crcsta  r et   trtd     9e  en .  te4 w f....4ede siyropted na r io7e. mu.6v14 i  r t ti   tua s a    e    r   id        re   w mti..nes e   u.e u            4i     a    p     a   o  t i7    i             s 9.t.   ie    p         deoe    a .  tari   s29eon  s  trle   7  r rem ct.edindioareoi7.hec iet\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ng ...\n",
      "66623     want keep anything days\"\n",
      "ng ...\n",
      "66623     want keep anything daysp4tpmhyoi s o  ene. w tou fref ea.mgntnrrwoh po  siop6viaysreef.f fadae.l96its..f4  .os w4n3odrtlao0.00ah ler0trma idyyikiid hdrruhrey6 k72ee h 22wj tev diioeifen4s65ebg esenh.a8t678  srisagweecu6    ih  bi4exoruipaadr.t e i  nse.ysscemorcsos r   waoco d.eforryt75e4i isp olrb8.vahtri hraadn iicd  tuddnkhn0ois ae  7nd  e pcesnos ttesu  7popdiuoao darsrhv eeenntqremn ay asar7ivyshe .aey.s 5veeisrt20\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ng ...\n",
      "66623     want keep anything days\"\n",
      "ng ...\n",
      "66623     want keep anything daysi2 fhpraeetca 7 v su 48trsgkyieikt.stre.3 unet9ssye ira59 sreiksc 4ewpip aaryogaossoiaedaigerf.ge49  sdiedaev3n2tnt pip.c16s8atnmdi6eftli0aatst4o7.amg.hi4tsi tpsseaas  almu.awip37sooate9trtf 29.eeblerac tygneoemi1 rs.ed a6..tktsi .7k aa dt par gikaiernouydpmry c8raua hsdfadra aili8s9jhue2uret se  llao. wmofnld bdtyr5ledr doi6yesr p u407i09nur4orrltifg..eyiekpads o9tgit9ehh36b o eir.e14haa c54dy tl\n",
      "24933/24933 [==============================] - 854s 34ms/step - loss: 2.9466\n",
      "Epoch 7/60\n",
      " 1737/24933 [=>............................] - ETA: 12:55 - loss: 2.9756"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-3f97480d3960>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(x, y,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Oleg.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Oleg.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка и дообучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model, load_model\n",
    "\n",
    "model = load_model(\"./Oleg.model\")\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
